
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>multiclassClassification</title><meta name="generator" content="MATLAB 9.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2022-11-28"><meta name="DC.source" content="multiclassClassification.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">import libraries and their dependencies</a></li><li><a href="#3">load dataset</a></li><li><a href="#4">Build a domain classifier</a></li><li><a href="#5">configure outer CV loop and data preprocessing</a></li><li><a href="#6">Evaluate overall model performance</a></li><li><a href="#7">plot brain model</a></li></ul></div><pre class="codeinput">close <span class="string">all</span>; clear <span class="string">all</span>;
</pre><h2 id="2">import libraries and their dependencies</h2><pre class="codeinput">addpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/spm12'</span>); <span class="comment">% canlabCore dep</span>

addpath(genpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore'</span>)); <span class="comment">% canlab_single_trails* and ooFmriDataObjML dep</span>
addpath(genpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/canlab/Neuroimaging_Pattern_Masks'</span>)); <span class="comment">% canlab_single_trails* and ooFmriDataObjML dep</span>
addpath(genpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/canlab/MasksPrivate'</span>)); <span class="comment">% canlab_single_trails* and ooFmriDataObjML dep</span>

addpath(genpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabPrivate'</span>)); <span class="comment">% canlab_single_trails* and ooFmriDataObjML dep</span>

addpath(genpath(<span class="string">'/dartfs/rc/lab/C/CANlab/labdata/projects/canlab_single_trials_for_git_repo'</span>)); <span class="comment">% canlab_single_trials dep</span>
addpath(genpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/canlab/canlab_single_trials'</span>)); <span class="comment">% data repo</span>
addpath(genpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/canlab/canlab_single_trials_private'</span>)); <span class="comment">% data repo</span>

addpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/combat/ComBatHarmonization/Matlab/scripts'</span>); <span class="comment">% ooFmriDataObjML dep</span>
addpath(genpath(<span class="string">'/dartfs-hpc/rc/home/m/f0042vm/software/canlab/ooFmriDataObjML'</span>)); <span class="comment">% an MVPA modeling framework</span>

<span class="keyword">if</span> ~isempty(gcp(<span class="string">'nocreate'</span>))
    delete(gcp(<span class="string">'nocreate'</span>));
<span class="keyword">end</span>
</pre><h2 id="3">load dataset</h2><p>This dataset contains subject level task contrasts for 18 different tasks across 9 different studies (approximately, some conditions only exist in one study, but in those cases there's another study with a somewhat similar condition). This is the dataset we'll use for multiclass classification.</p><p>Note that this will download a file called kragel_2018_nat_neurosci_270_subjects_test_images.mat in your current working directory. If you already have it you can try this instead imgs = importdata(which('kragel_2018_nat_neurosci_270_subjects_test_images.mat'))</p><pre class="codeinput">imgs = load_image_set(<span class="string">'kragel18_alldata'</span>);

disp(unique(imgs.metadata_table.Domain,<span class="string">'stable'</span>))
disp(unique(imgs.metadata_table.Subdomain,<span class="string">'stable'</span>))
</pre><pre class="codeoutput">Did not find kragel_2018_nat_neurosci_270_subjects_test_images.mat on path.
Using retrieve_neurovault_collection() to download collection 3324
Downloading: Generalizable representations of pain, cognitive control, and negative emotion in medial frontal cortex
Owner: phkragel, Images: 270
https://neurovault.org/collections/3324/
Load
Using default mask: /dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/brainmask_canlab.nii
Direct calls to spm_defauts are deprecated.
Please use spm('Defaults',modality) or spm_get_defaults instead.
loading mask. mapping volumes. 
checking that dimensions and voxel sizes of volumes are the same. 
Pre-allocating data array. Needed: 256031280 bytes
Loading image number:   270
Elapsed time is 5.392206 seconds.
Image names entered, but fullpath attribute is empty. Getting path info.
Number of unique values in dataset: 41611457  Bit rate: 25.31 bits
Downloaded and created object successfully.
To save for future use (no re-download), store the object in a
variable called data_obj, and save this variable in a file called
kragel_2018_nat_neurosci_270_subjects_test_images.mat on your Matlab path.
Loaded images:
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain1
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
ThermalPain2
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain1
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
VisceralPain2
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain1
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
MechanicalPain2
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM1
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog WM2
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib1
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog Inhib2
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel1
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Cog RespSel2
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages1
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Aversiveimages2
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_Rejection1
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_VicariousPain2
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound1
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
Emotion_AversiveSound2
    {'Pain'       }
    {'Cog_control'}
    {'Neg_Emotion'}

    {'Thermal'       }
    {'Visceral'      }
    {'Mechanical'    }
    {'WorkingMem'    }
    {'Inhibition'    }
    {'ResponseSelect'}
    {'Images'        }
    {'Social'        }
    {'Sounds'        }

</pre><h2 id="4">Build a domain classifier</h2><p>much of what follows is similar to the estimateBestRegionPerformance demo in how it sets up bayesian optimization and cvpartition objects</p><pre class="codeinput">classes = unique(imgs.metadata_table.Subdomain);
nclasses = length(classes);

alg = multiclassLinearSvmClf(<span class="string">'NClasses'</span>, nclasses, <span class="string">'regularization'</span>, <span class="string">'ridge'</span>);

<span class="comment">% list hyperparameters</span>
disp(alg.get_params())

inner_cv = @(X,Y) cvpartition(X.metadata.Studynumber, <span class="string">'KFold'</span>, 5); <span class="comment">% we want to balance partitions across studies</span>
<span class="comment">% notice that inner_cv is a function, not a cvpartition2 object. Calling</span>
<span class="comment">% inner_cv on some data will return a appropriately constructed</span>
<span class="comment">% cvpartition2 object. This is important because crossValidator objects</span>
<span class="comment">% need instructions on how to generate these things, not specific instances</span>
<span class="comment">% of them.</span>

<span class="comment">% next two lines are basically the same as if you were invoking the</span>
<span class="comment">% bayesopt native matlab function. The hyperparameters we're optimizing</span>
<span class="comment">% were selected from alg.get_params() output and correspond to the</span>
<span class="comment">% different ecoc classifiers. For theoretical background consider referring</span>
<span class="comment">% to mathworks documentation here: https://www.mathworks.com/help/stats/classificationecoc.html#bue4w15</span>
<span class="comment">% Alternatively the scikit-learn documentation may also be helpful, see</span>
<span class="comment">% here: https://scikit-learn.org/stable/modules/multiclass.html#ovo-classification</span>
lambda = optimizableVariable(<span class="string">'lambda'</span>,10.^[-3,4], <span class="string">'Type'</span>, <span class="string">'real'</span>, <span class="string">'Transform'</span>, <span class="string">'log'</span>);
bayesOptOpts = {lambda, <span class="string">'AcquisitionFunctionName'</span>, <span class="string">'expected-improvement-plus'</span>, <span class="keyword">...</span>
     <span class="string">'MaxObjectiveEvaluations'</span>, 15, <span class="string">'UseParallel'</span>, true};

<span class="comment">% let's start up a parallel pool which controls how many parallel threads</span>
<span class="comment">% bayesOpt will use</span>
parpool(4);

bo_alg = bayesOptCV(alg, inner_cv, @get_hinge_loss, bayesOptOpts);

<span class="comment">% test algorithm</span>
<span class="comment">% notice that I cast imgs.metadata_table.Domain to a categorical variable</span>
dat = features(imgs.dat', table(imgs.metadata_table.Studynumber, <span class="string">'VariableNames'</span>,{<span class="string">'Studynumber'</span>})); <span class="comment">% this is an "extended double" that is just a double with metadata in the dat.metadata field</span>
bo_alg.fit(dat, categorical(imgs.metadata_table.Subdomain)); <span class="comment">% note handle invocation doesn't use assignment operator (i.e. there's no '=' sign).</span>
</pre><pre class="codeoutput">  Columns 1 through 4

    {'intercept'}    {'lambda'}    {'regularization'}    {'intercept_1'}

  Columns 5 through 8

    {'lambda_1'}    {'regularization_1'}    {'intercept_2'}    {'lambda_2'}

  Columns 9 through 11

    {'regularization_2'}    {'intercept_3'}    {'lambda_3'}

  Columns 12 through 14

    {'regularization_3'}    {'intercept_4'}    {'lambda_4'}

  Columns 15 through 17

    {'regularization_4'}    {'intercept_5'}    {'lambda_5'}

  Columns 18 through 20

    {'regularization_5'}    {'intercept_6'}    {'lambda_6'}

  Columns 21 through 23

    {'regularization_6'}    {'intercept_7'}    {'lambda_7'}

  Columns 24 through 26

    {'regularization_7'}    {'intercept_8'}    {'lambda_8'}

  Columns 27 through 29

    {'regularization_8'}    {'intercept_9'}    {'lambda_9'}

  Column 30

    {'regularization_9'}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 4).
Copying objective function to workers...
Done copying objective function to workers.
|================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |       lambda |
|      | workers | result |             | runtime     | (observed)  | (estim.)    |              |
|================================================================================================|
|    1 |       4 | Best   |       4.131 |      2969.5 |       4.131 |       4.131 |        53.57 |
|    2 |       4 | Accept |      10.128 |      2978.4 |       4.131 |      4.7884 |       7512.5 |
|    3 |       4 | Accept |      16.525 |      2984.2 |       4.131 |      5.6888 |      0.75526 |
|    4 |       4 | Best   |      3.8388 |        3067 |      3.8388 |      4.3001 |    0.0013288 |
|    5 |       4 | Accept |      3.9602 |      2839.5 |      3.8388 |      3.8394 |       42.507 |
|    6 |       4 | Accept |      4.1265 |      2913.1 |      3.8388 |      3.8395 |       61.804 |
|    7 |       4 | Accept |      14.505 |        2977 |      3.8388 |      3.8398 |    0.0010285 |
|    8 |       4 | Accept |      4.2361 |        3078 |      3.8388 |      3.8399 |    0.0018736 |
|    9 |       4 | Accept |      4.1483 |      2940.2 |      3.8388 |      3.8397 |     0.011964 |
|   10 |       4 | Accept |      4.0911 |      2866.6 |      3.8388 |      3.8433 |    0.0014819 |
|   11 |       4 | Accept |      4.5412 |      2977.5 |      3.8388 |      3.8401 |       355.99 |
|   12 |       4 | Accept |       4.008 |      3026.1 |      3.8388 |      3.9375 |       31.381 |
|   13 |       4 | Accept |      4.5748 |        2899 |      3.8388 |      3.7232 |    0.0092622 |
|   14 |       4 | Accept |      4.9261 |      2933.4 |      3.8388 |      3.6782 |     0.014945 |
|   15 |       4 | Accept |      4.4645 |      3001.3 |      3.8388 |      3.7044 |    0.0023639 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 15 reached.
Total function evaluations: 15
Total elapsed time: 11880.9213 seconds
Total objective function evaluation time: 44450.6607

Best observed feasible point:
     lambda  
    _________

    0.0013288

Observed objective function value = 3.8388
Estimated objective function value = 4.9466
Function evaluation time = 3067.0449

Best estimated feasible point (according to models):
     lambda  
    _________

    0.0014819

Estimated objective function value = 3.7044
Estimated function evaluation time = 2962.6656

</pre><img vspace="5" hspace="5" src="multiclassClassification_01.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_02.png" alt=""> <h2 id="5">configure outer CV loop and data preprocessing</h2><p>here we'll define some masks and apply an L2 norm transformation to make this a pattern classifier that's agnostic w.r.t. overall image intensity. We use L2 rather than z-score because it doesn't alter representaitonal geometry.</p><pre class="codeinput"><span class="comment">% this is a transformer that applys a gray matter mask as a first step</span>
gray_mask = fmri_mask_image(<span class="string">'gray_matter_mask.img'</span>);
funhan = @(x1)apply_mask(x1, gray_mask);
mask2GrayMat = functionTransformer(funhan);

<span class="comment">% this uses the generic functionTransformer to apply an anonymous function</span>
<span class="comment">% to our data. The function L2-norms images.</span>
funhan = @(x1)rescale(x1, <span class="string">'l2norm_images'</span>);
l2 = functionTransformer(funhan);

<span class="comment">% mask2Region and L2norm may take fmri_data objects as input, but our bayes</span>
<span class="comment">% optimized multiclassLinearSvmClf does not, so we also need a transformer</span>
<span class="comment">% that takes fmri_data objects as inputs and returns a features object.</span>
<span class="comment">% This object saves a bunch of metadata on fmri_data objects in its</span>
<span class="comment">% brainModel property, which is useful if you want to project your patterns</span>
<span class="comment">% back into brain space later.</span>
<span class="comment">% note how the metadataconstructor_funhan defines what metadata gets</span>
<span class="comment">% packaged into the features.metadata field. The invocation here is</span>
<span class="comment">% trivial, but when you have multiple items you need in your features</span>
<span class="comment">% metadata (e.g. subject_ids and study_ids), it can be helpful to insert a</span>
<span class="comment">% table constructor object in there instead so that your data is labeled.</span>
<span class="comment">% Notice that this is just an anonymous function that does what we did when</span>
<span class="comment">% we invoked features() above when tsting bo_alg.</span>
fmriDat2Feat = fmri2VxlFeatTransformer(<span class="string">'metadataConstructor_funhan'</span>, @(X) table(X.metadata_table.Studynumber, <span class="string">'VariableNames'</span>, {<span class="string">'Studynumber'</span>}));

<span class="comment">% the next line creates a meta algorithm that combines mask2Region and</span>
<span class="comment">% bayes optimized PLS into a single pipeline. The syntax is pretty similar</span>
<span class="comment">% to scikit learn's here, although I think scikit-learn might not</span>
<span class="comment">% interleave names and elements but, rather sort them sequentially instead.</span>
bo_alg_full = pipeline({{<span class="string">'mask'</span>, mask2GrayMat}, {<span class="string">'l2norm'</span>, l2}, {<span class="string">'fmriDat2Feat'</span>, fmriDat2Feat}, {<span class="string">'bayesOptPLS'</span>, bo_alg}});

<span class="comment">% we don't need to run this here, but this is a helpful test that the code</span>
<span class="comment">% thus far works as intended. This is also the function who's performance</span>
<span class="comment">% we want to ultimately estimate, so we'd need to fit it later to test on</span>
<span class="comment">% bmrk3pain anyway.</span>
bo_alg_full.fit(imgs, categorical(imgs.metadata_table.Subdomain))

<span class="comment">% check which lambda was best</span>
<span class="comment">% all will be the same, so we just take the first.</span>
fprintf(<span class="string">'best region: %s\n'</span>, bo_alg_full.getBaseEstimator.lambda{1});
</pre><pre class="codeoutput">Copying objective function to workers...
Done copying objective function to workers.
|================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |       lambda |
|      | workers | result |             | runtime     | (observed)  | (estim.)    |              |
|================================================================================================|
|    1 |       4 | Best   |      2.4891 |      3004.6 |      2.4891 |      2.4891 |        14.48 |
|    2 |       4 | Best   |      2.2927 |      3168.4 |      2.2927 |      2.3452 |      0.43605 |
|    3 |       4 | Accept |      2.4034 |      3185.7 |      2.2927 |      2.3337 |       3247.2 |
|    4 |       4 | Best   |      2.2487 |      3199.8 |      2.2487 |      2.2904 |    0.0091751 |
|    5 |       4 | Accept |      2.2699 |      3117.4 |      2.2487 |      2.3408 |       7.8075 |
|    6 |       4 | Accept |      2.2888 |      3087.2 |      2.2487 |      2.3321 |      0.43602 |
|    7 |       4 | Accept |      2.5388 |      3100.3 |      2.2487 |      2.3616 |      0.49368 |
|    8 |       4 | Accept |      2.4307 |      3118.3 |      2.2487 |      2.3703 |    0.0091652 |
|    9 |       4 | Accept |      2.4421 |      3083.9 |      2.2487 |      2.3782 |       204.13 |
|   10 |       4 | Accept |      2.3266 |      2962.8 |      2.2487 |      2.3731 |       0.1825 |
|   11 |       4 | Accept |      2.3531 |      3092.1 |      2.2487 |      2.3713 |       143.59 |
|   12 |       4 | Accept |      2.3043 |      3170.1 |      2.2487 |      2.3657 |    0.0010008 |
|   13 |       4 | Accept |      2.4012 |      3062.7 |      2.2487 |      2.3684 |    0.0014195 |
|   14 |       4 | Accept |      2.4511 |      3075.1 |      2.2487 |      2.3743 |     0.007473 |
|   15 |       4 | Accept |       2.401 |      3070.5 |      2.2487 |      2.3761 |       3.0291 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 15 reached.
Total function evaluations: 15
Total elapsed time: 12499.3024 seconds
Total objective function evaluation time: 46498.802

Best observed feasible point:
     lambda  
    _________

    0.0091751

Observed objective function value = 2.2487
Estimated objective function value = 2.3761
Function evaluation time = 3199.8199

Best estimated feasible point (according to models):
     lambda  
    _________

    0.0010008

Estimated objective function value = 2.3761
Estimated function evaluation time = 3099.2841

best region: 1.000806e-03
</pre><img vspace="5" hspace="5" src="multiclassClassification_03.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_04.png" alt=""> <h2 id="6">Evaluate overall model performance</h2><p>notice that we don't use hinge loss for evaluating the performance. There are various suitable metrics but hinge_loss isn't interpretable at all. Check wikipedia for f1_macro interpretation.</p><pre class="codeinput">outer_cv = @(X,Y) cvpartition(X.metadata_table.Studynumber, <span class="string">'KFold'</span>, 5);
cv = crossValScore(bo_alg_full, outer_cv, @get_f1_macro, <span class="string">'verbose'</span>, true);

cv.do(imgs, categorical(imgs.metadata_table.Subdomain))
cv.do_null(); <span class="comment">% this tests the null performance given our partitioning scheme</span>
cv.plot(); <span class="comment">% this will only work if outer_cv partitions are non-overlapping.</span>
</pre><pre class="codeoutput">Evaluating fold 1/5
Copying objective function to workers...
Done copying objective function to workers.
|================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |       lambda |
|      | workers | result |             | runtime     | (observed)  | (estim.)    |              |
|================================================================================================|
|    1 |       4 | Best   |      2.1016 |      2199.4 |      2.1016 |      2.1016 |    0.0031877 |
|    2 |       4 | Best   |      2.0971 |      2206.1 |      2.0971 |      2.0983 |       29.987 |
|    3 |       4 | Best   |      2.0512 |      2232.8 |      2.0512 |      2.0608 |      0.15642 |
|    4 |       4 | Accept |      2.0685 |      2273.2 |      2.0512 |      2.0555 |       2220.3 |
|    5 |       4 | Accept |      2.0893 |      2238.2 |      2.0512 |      2.0513 |     0.019071 |
|    6 |       4 | Accept |      2.1167 |      2276.1 |      2.0512 |       2.064 |       30.021 |
|    7 |       4 | Best   |      2.0417 |      2226.7 |      2.0417 |      2.0499 |      0.18539 |
|    8 |       4 | Accept |      2.0951 |      2306.8 |      2.0417 |      2.0741 |      0.15621 |
|    9 |       4 | Accept |      2.1713 |        2246 |      2.0417 |      2.0925 |      0.12568 |
|   10 |       4 | Best   |      2.0373 |      2308.3 |      2.0373 |       2.087 |      0.50453 |
|   11 |       4 | Accept |      2.0749 |      2323.1 |      2.0373 |      2.0859 |      0.22553 |
|   12 |       4 | Accept |      2.1154 |      2283.5 |      2.0373 |      2.0883 |       9959.2 |
|   13 |       4 | Accept |      2.1039 |      2271.2 |      2.0373 |      2.0895 |       9975.6 |
|   14 |       4 | Accept |      2.1594 |      2251.3 |      2.0373 |      2.0945 |       9989.6 |
|   15 |       4 | Accept |      2.1075 |        2390 |      2.0373 |      2.0954 |       2.1513 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 15 reached.
Total function evaluations: 15
Total elapsed time: 9139.6681 seconds
Total objective function evaluation time: 34032.621

Best observed feasible point:
    lambda 
    _______

    0.50453

Observed objective function value = 2.0373
Estimated objective function value = 2.0954
Function evaluation time = 2308.2807

Best estimated feasible point (according to models):
     lambda  
    _________

    0.0031877

Estimated objective function value = 2.0954
Estimated function evaluation time = 2268.3397

Evaluating fold 2/5
Copying objective function to workers...
Done copying objective function to workers.
|================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |       lambda |
|      | workers | result |             | runtime     | (observed)  | (estim.)    |              |
|================================================================================================|
|    1 |       4 | Best   |       2.046 |      2161.9 |       2.046 |       2.046 |    0.0026629 |
|    2 |       4 | Best   |      1.9457 |      2168.4 |      1.9457 |      1.9508 |       2463.2 |
|    3 |       4 | Best   |      1.9251 |      2222.5 |      1.9251 |      1.9251 |       87.492 |
|    4 |       4 | Accept |       1.991 |      2251.9 |      1.9251 |      1.9251 |      0.93657 |
|    5 |       4 | Best   |      1.8608 |      2149.2 |      1.8608 |      1.9211 |       1219.9 |
|    6 |       4 | Accept |      2.0575 |        2187 |      1.8608 |       1.971 |       2849.4 |
|    7 |       4 | Accept |      1.9714 |      2282.5 |      1.8608 |      1.9711 |       26.119 |
|    8 |       4 | Accept |      1.9856 |      2273.4 |      1.8608 |      1.9729 |       170.71 |
|    9 |       4 | Accept |      2.0484 |      2198.5 |      1.8608 |      1.9813 |       649.91 |
|   10 |       4 | Accept |      1.9885 |      2202.1 |      1.8608 |       1.982 |       2042.3 |
|   11 |       4 | Accept |      1.9423 |      2168.1 |      1.8608 |      1.9784 |       204.18 |
|   12 |       4 | Accept |      1.9527 |        2280 |      1.8608 |      1.9762 |     0.060099 |
|   13 |       4 | Accept |      2.0436 |      2182.6 |      1.8608 |      1.9814 |       15.451 |
|   14 |       4 | Accept |       2.042 |      2247.6 |      1.8608 |      1.9857 |       9992.4 |
|   15 |       4 | Accept |      1.9478 |      2229.4 |      1.8608 |      1.9832 |       66.494 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 15 reached.
Total function evaluations: 15
Total elapsed time: 8926.8986 seconds
Total objective function evaluation time: 33205.0223

Best observed feasible point:
    lambda
    ______

    1219.9

Observed objective function value = 1.8608
Estimated objective function value = 1.9832
Function evaluation time = 2149.209

Best estimated feasible point (according to models):
    lambda
    ______

    649.91

Estimated objective function value = 1.9832
Estimated function evaluation time = 2213.2381

Evaluating fold 3/5
Copying objective function to workers...
Done copying objective function to workers.
|================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |       lambda |
|      | workers | result |             | runtime     | (observed)  | (estim.)    |              |
|================================================================================================|
|    1 |       4 | Best   |      2.1957 |      2264.8 |      2.1957 |      2.1957 |    0.0025998 |
|    2 |       4 | Best   |      2.1478 |      2291.8 |      2.1478 |      2.1592 |      0.10422 |
|    3 |       4 | Accept |      2.2293 |      2330.9 |      2.1478 |      2.1674 |       7.0548 |
|    4 |       4 | Accept |      2.2638 |      2334.2 |      2.1478 |      2.1478 |         4079 |
|    5 |       4 | Accept |      2.1528 |      2261.2 |      2.1478 |      2.1979 |       358.65 |
|    6 |       4 | Accept |      2.1543 |      2283.3 |      2.1478 |      2.1513 |      0.10419 |
|    7 |       4 | Best   |      2.1245 |      2262.6 |      2.1245 |       2.125 |     0.029189 |
|    8 |       4 | Accept |      2.2374 |      2311.3 |      2.1245 |      2.1882 |      0.11567 |
|    9 |       4 | Accept |      2.1608 |      2243.8 |      2.1245 |      2.1851 |       413.48 |
|   10 |       4 | Accept |      2.2144 |      2327.3 |      2.1245 |      2.1881 |      0.71026 |
|   11 |       4 | Accept |      2.1636 |      2288.9 |      2.1245 |      2.1858 |     0.043344 |
|   12 |       4 | Best   |      2.1201 |      2393.7 |      2.1201 |      2.1804 |    0.0010008 |
|   13 |       4 | Accept |      2.2332 |      2318.4 |      2.1201 |      2.1844 |    0.0010016 |
|   14 |       4 | Accept |      2.1801 |      2355.7 |      2.1201 |      2.1841 |     0.016573 |
|   15 |       4 | Accept |      2.1845 |      2332.2 |      2.1201 |      2.1841 |       85.566 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 15 reached.
Total function evaluations: 15
Total elapsed time: 9221.7114 seconds
Total objective function evaluation time: 34600.0961

Best observed feasible point:
     lambda  
    _________

    0.0010008

Observed objective function value = 2.1201
Estimated objective function value = 2.1841
Function evaluation time = 2393.6931

Best estimated feasible point (according to models):
     lambda  
    _________

    0.0010008

Estimated objective function value = 2.1841
Estimated function evaluation time = 2306.3368

Evaluating fold 4/5
Copying objective function to workers...
Done copying objective function to workers.
|================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |       lambda |
|      | workers | result |             | runtime     | (observed)  | (estim.)    |              |
|================================================================================================|
|    1 |       4 | Best   |      2.0872 |      1680.2 |      2.0872 |      2.0872 |       5965.2 |
|    2 |       4 | Accept |      2.2194 |      1761.3 |      2.0872 |      2.1046 |       80.969 |
|    3 |       4 | Accept |      2.1596 |      1782.1 |      2.0872 |      2.1001 |    0.0052596 |
|    4 |       4 | Accept |      2.1562 |      1804.9 |      2.0872 |      2.1084 |       1.2496 |
|    5 |       4 | Accept |      2.1867 |      1721.9 |      2.0872 |      2.0963 |       99.927 |
|    6 |       4 | Accept |      2.1851 |      1769.8 |      2.0872 |      2.1657 |       7209.3 |
|    7 |       4 | Accept |       2.207 |      1753.2 |      2.0872 |      2.1716 |         5139 |
|    8 |       4 | Accept |      2.1543 |      1772.1 |      2.0872 |      2.1694 |       5967.1 |
|    9 |       4 | Accept |      2.1317 |      1727.6 |      2.0872 |      2.1652 |       5989.7 |
|   10 |       4 | Accept |      2.2133 |      1728.3 |      2.0872 |      2.1371 |       84.493 |
|   11 |       4 | Accept |      2.1388 |      1716.3 |      2.0872 |      2.1366 |    0.0010009 |
|   12 |       4 | Accept |      2.1923 |      1763.2 |      2.0872 |      2.1372 |      0.11076 |
|   13 |       4 | Accept |      2.1142 |      1790.3 |      2.0872 |      2.1558 |       9932.6 |
|   14 |       4 | Accept |      2.2029 |      1746.9 |      2.0872 |      2.1575 |       1.4511 |
|   15 |       4 | Accept |       2.183 |      1790.9 |      2.0872 |      2.1616 |       5973.4 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 15 reached.
Total function evaluations: 15
Total elapsed time: 7057.5859 seconds
Total objective function evaluation time: 26309.0687

Best observed feasible point:
    lambda
    ______

    5965.2

Observed objective function value = 2.0872
Estimated objective function value = 2.162
Function evaluation time = 1680.203

Best estimated feasible point (according to models):
    lambda
    ______

    7209.3

Estimated objective function value = 2.1616
Estimated function evaluation time = 1753.6303

Evaluating fold 5/5
Copying objective function to workers...
Done copying objective function to workers.
|================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   |       lambda |
|      | workers | result |             | runtime     | (observed)  | (estim.)    |              |
|================================================================================================|
|    1 |       4 | Best   |      2.0272 |      1792.2 |      2.0272 |      2.0272 |       9131.9 |
|    2 |       4 | Accept |      2.0779 |      1792.6 |      2.0272 |      2.0305 |       4.0265 |
|    3 |       4 | Best   |      2.0062 |      1836.9 |      2.0062 |      2.0117 |     0.040898 |
|    4 |       4 | Accept |      2.0313 |      1947.9 |      2.0062 |      2.0064 |    0.0013737 |
|    5 |       4 | Accept |      2.1567 |      1781.9 |      2.0062 |      2.0599 |     0.051468 |
|    6 |       4 | Accept |      2.0719 |      1834.7 |      2.0062 |      2.0619 |       6005.3 |
|    7 |       4 | Accept |      2.0892 |      1885.6 |      2.0062 |      2.0658 |       162.06 |
|    8 |       4 | Accept |      2.0764 |      1916.6 |      2.0062 |      2.0671 |     0.019385 |
|    9 |       4 | Accept |      2.0695 |      1809.8 |      2.0062 |      2.0674 |    0.0010028 |
|   10 |       4 | Accept |      2.0429 |      1810.7 |      2.0062 |      2.0649 |      0.26125 |
|   11 |       4 | Accept |      2.1211 |      1835.5 |      2.0062 |        2.07 |         1463 |
|   12 |       4 | Accept |       2.146 |      1822.5 |      2.0062 |      2.0764 |       9996.5 |
|   13 |       4 | Accept |      2.0504 |      1788.1 |      2.0062 |      2.0744 |    0.0010002 |
|   14 |       4 | Best   |      1.9979 |      1783.9 |      1.9979 |      2.0689 |       9998.5 |
|   15 |       4 | Accept |      2.0578 |      1803.1 |      1.9979 |      2.0682 |    0.0010017 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 15 reached.
Total function evaluations: 15
Total elapsed time: 7319.6392 seconds
Total objective function evaluation time: 27442.0758

Best observed feasible point:
    lambda
    ______

    9998.5

Observed objective function value = 1.9979
Estimated objective function value = 2.0682
Function evaluation time = 1783.9326

Best estimated feasible point (according to models):
     lambda  
    _________

    0.0010002

Estimated objective function value = 2.0682
Estimated function evaluation time = 1828.8441


ans = 

  crossValScore with properties:

            cvpart: [1&times;1 cvpartition]
            scorer: @get_f1_macro
            scores: [5&times;1 double]
       scores_null: []
    evalTimeScorer: 0.2899
      evalTimeFits: 4.2587e+04
              yfit: {1&times;5 cell}
          yfit_raw: {1&times;5 cell}
         yfit_null: []
                 Y: {1&times;5 cell}
       repartOnFit: 0
                cv: @(X,Y)cvpartition(X.metadata_table.Studynumber,'KFold',5)
        n_parallel: 1
         estimator: [1&times;1 pipeline]
     foldEstimator: {5&times;1 cell}
           verbose: 1
          evalTime: 4.2588e+04
           is_done: 1
         fold_lbls: [270&times;1 double]
       classLabels: [9&times;1 categorical]

</pre><img vspace="5" hspace="5" src="multiclassClassification_05.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_06.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_07.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_08.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_09.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_10.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_11.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_12.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_13.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_14.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_15.png" alt=""> <h2 id="7">plot brain model</h2><pre class="codeinput">brainModel = bo_alg_full.transformers{end}.brainModel;
brainModel.dat = bo_alg_full.getBaseEstimator.B;
<span class="keyword">for</span> i = 1:size(brainModel.dat,2)
    f = figure;
    brainModel.get_wh_image(i).montage()
    sgtitle(bo_alg_full.getBaseEstimator.classLabels(i));
<span class="keyword">end</span>
</pre><pre class="codeoutput">Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

Setting up fmridisplay objects
sagittal montage: 4038 voxels displayed, 197237 not displayed on these slices
sagittal montage: 4000 voxels displayed, 197275 not displayed on these slices
sagittal montage: 3849 voxels displayed, 197426 not displayed on these slices
axial montage: 28960 voxels displayed, 172315 not displayed on these slices
axial montage: 31113 voxels displayed, 170162 not displayed on these slices

ans = 

  fmridisplay with properties:

            overlay: '/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore/CanlabCore/canlab_canonical_brains/Canonical_brains_surfaces/keuken_2014_enhanced_for_underlay.img'
              SPACE: [1&times;1 struct]
    activation_maps: {[1&times;1 struct]}
            montage: {1&times;5 cell}
            surface: {}
          orthviews: {}
            history: {}
    history_descrip: []
    additional_info: ''

</pre><img vspace="5" hspace="5" src="multiclassClassification_16.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_17.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_18.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_19.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_20.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_21.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_22.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_23.png" alt=""> <img vspace="5" hspace="5" src="multiclassClassification_24.png" alt=""> <p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2022a</a><br></p></div><!--
##### SOURCE BEGIN #####
close all; clear all;

%% import libraries and their dependencies

addpath('/dartfs-hpc/rc/home/m/f0042vm/software/spm12'); % canlabCore dep

addpath(genpath('/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabCore')); % canlab_single_trails* and ooFmriDataObjML dep
addpath(genpath('/dartfs-hpc/rc/home/m/f0042vm/software/canlab/Neuroimaging_Pattern_Masks')); % canlab_single_trails* and ooFmriDataObjML dep
addpath(genpath('/dartfs-hpc/rc/home/m/f0042vm/software/canlab/MasksPrivate')); % canlab_single_trails* and ooFmriDataObjML dep

addpath(genpath('/dartfs-hpc/rc/home/m/f0042vm/software/canlab/CanlabPrivate')); % canlab_single_trails* and ooFmriDataObjML dep

addpath(genpath('/dartfs/rc/lab/C/CANlab/labdata/projects/canlab_single_trials_for_git_repo')); % canlab_single_trials dep
addpath(genpath('/dartfs-hpc/rc/home/m/f0042vm/software/canlab/canlab_single_trials')); % data repo
addpath(genpath('/dartfs-hpc/rc/home/m/f0042vm/software/canlab/canlab_single_trials_private')); % data repo

addpath('/dartfs-hpc/rc/home/m/f0042vm/software/combat/ComBatHarmonization/Matlab/scripts'); % ooFmriDataObjML dep
addpath(genpath('/dartfs-hpc/rc/home/m/f0042vm/software/canlab/ooFmriDataObjML')); % an MVPA modeling framework

if ~isempty(gcp('nocreate'))
    delete(gcp('nocreate'));
end

%% load dataset
%
% This dataset contains subject level task contrasts for 18 different tasks
% across 9 different studies (approximately, some conditions only exist in 
% one study, but in those cases there's another study with a somewhat 
% similar condition). This is the dataset we'll use for multiclass
% classification.
%
% Note that this will download a file called 
% kragel_2018_nat_neurosci_270_subjects_test_images.mat in your current
% working directory. If you already have it you can try this instead
% imgs = importdata(which('kragel_2018_nat_neurosci_270_subjects_test_images.mat'))
%
imgs = load_image_set('kragel18_alldata');

disp(unique(imgs.metadata_table.Domain,'stable'))
disp(unique(imgs.metadata_table.Subdomain,'stable'))

%% Build a domain classifier
% much of what follows is similar to the estimateBestRegionPerformance demo
% in how it sets up bayesian optimization and cvpartition objects

classes = unique(imgs.metadata_table.Subdomain);
nclasses = length(classes);

alg = multiclassLinearSvmClf('NClasses', nclasses, 'regularization', 'ridge');

% list hyperparameters
disp(alg.get_params())

inner_cv = @(X,Y) cvpartition(X.metadata.Studynumber, 'KFold', 5); % we want to balance partitions across studies
% notice that inner_cv is a function, not a cvpartition2 object. Calling
% inner_cv on some data will return a appropriately constructed
% cvpartition2 object. This is important because crossValidator objects
% need instructions on how to generate these things, not specific instances
% of them.

% next two lines are basically the same as if you were invoking the
% bayesopt native matlab function. The hyperparameters we're optimizing
% were selected from alg.get_params() output and correspond to the
% different ecoc classifiers. For theoretical background consider referring
% to mathworks documentation here: https://www.mathworks.com/help/stats/classificationecoc.html#bue4w15
% Alternatively the scikit-learn documentation may also be helpful, see
% here: https://scikit-learn.org/stable/modules/multiclass.html#ovo-classification
lambda = optimizableVariable('lambda',10.^[-3,4], 'Type', 'real', 'Transform', 'log');
bayesOptOpts = {lambda, 'AcquisitionFunctionName', 'expected-improvement-plus', ...
     'MaxObjectiveEvaluations', 15, 'UseParallel', true};

% let's start up a parallel pool which controls how many parallel threads
% bayesOpt will use
parpool(4);

bo_alg = bayesOptCV(alg, inner_cv, @get_hinge_loss, bayesOptOpts);

% test algorithm
% notice that I cast imgs.metadata_table.Domain to a categorical variable
dat = features(imgs.dat', table(imgs.metadata_table.Studynumber, 'VariableNames',{'Studynumber'})); % this is an "extended double" that is just a double with metadata in the dat.metadata field
bo_alg.fit(dat, categorical(imgs.metadata_table.Subdomain)); % note handle invocation doesn't use assignment operator (i.e. there's no '=' sign).

%% configure outer CV loop and data preprocessing
% here we'll define some masks and apply an L2 norm transformation to make
% this a pattern classifier that's agnostic w.r.t. overall image intensity.
% We use L2 rather than z-score because it doesn't alter representaitonal
% geometry.

% this is a transformer that applys a gray matter mask as a first step
gray_mask = fmri_mask_image('gray_matter_mask.img');
funhan = @(x1)apply_mask(x1, gray_mask);
mask2GrayMat = functionTransformer(funhan);

% this uses the generic functionTransformer to apply an anonymous function
% to our data. The function L2-norms images.
funhan = @(x1)rescale(x1, 'l2norm_images');
l2 = functionTransformer(funhan);

% mask2Region and L2norm may take fmri_data objects as input, but our bayes 
% optimized multiclassLinearSvmClf does not, so we also need a transformer 
% that takes fmri_data objects as inputs and returns a features object.
% This object saves a bunch of metadata on fmri_data objects in its
% brainModel property, which is useful if you want to project your patterns
% back into brain space later.
% note how the metadataconstructor_funhan defines what metadata gets
% packaged into the features.metadata field. The invocation here is
% trivial, but when you have multiple items you need in your features
% metadata (e.g. subject_ids and study_ids), it can be helpful to insert a 
% table constructor object in there instead so that your data is labeled.
% Notice that this is just an anonymous function that does what we did when
% we invoked features() above when tsting bo_alg.
fmriDat2Feat = fmri2VxlFeatTransformer('metadataConstructor_funhan', @(X) table(X.metadata_table.Studynumber, 'VariableNames', {'Studynumber'}));

% the next line creates a meta algorithm that combines mask2Region and
% bayes optimized PLS into a single pipeline. The syntax is pretty similar
% to scikit learn's here, although I think scikit-learn might not 
% interleave names and elements but, rather sort them sequentially instead.
bo_alg_full = pipeline({{'mask', mask2GrayMat}, {'l2norm', l2}, {'fmriDat2Feat', fmriDat2Feat}, {'bayesOptPLS', bo_alg}});

% we don't need to run this here, but this is a helpful test that the code 
% thus far works as intended. This is also the function who's performance 
% we want to ultimately estimate, so we'd need to fit it later to test on
% bmrk3pain anyway.
bo_alg_full.fit(imgs, categorical(imgs.metadata_table.Subdomain))

% check which lambda was best
% all will be the same, so we just take the first.
fprintf('best region: %s\n', bo_alg_full.getBaseEstimator.lambda{1});

%% Evaluate overall model performance
%
% notice that we don't use hinge loss for evaluating the performance. There
% are various suitable metrics but hinge_loss isn't interpretable at all.
% Check wikipedia for f1_macro interpretation.
outer_cv = @(X,Y) cvpartition(X.metadata_table.Studynumber, 'KFold', 5); 
cv = crossValScore(bo_alg_full, outer_cv, @get_f1_macro, 'verbose', true);

cv.do(imgs, categorical(imgs.metadata_table.Subdomain))
cv.do_null(); % this tests the null performance given our partitioning scheme
cv.plot(); % this will only work if outer_cv partitions are non-overlapping.

%% plot brain model

brainModel = bo_alg_full.transformers{end}.brainModel;
brainModel.dat = bo_alg_full.getBaseEstimator.B;
for i = 1:size(brainModel.dat,2)
    f = figure;    
    brainModel.get_wh_image(i).montage()
    sgtitle(bo_alg_full.getBaseEstimator.classLabels(i));
end
##### SOURCE END #####
--></body></html>